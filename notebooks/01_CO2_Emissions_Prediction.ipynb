{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c6e1db",
   "metadata": {},
   "source": [
    "# CO2 Emissions Prediction — ETL WDI (World Bank)\n",
    "\n",
    "## Objetivo\n",
    "Extrair indicadores do World Development Indicators (WDI) via API do Banco Mundial e gerar:\n",
    "\n",
    "- `data/raw/wdi_long.csv` (formato longo: país–indicador–ano–valor)\n",
    "- `data/processed/wdi_wide.csv` (formato wide estilo Kaggle: 1 linha por país+indicador, colunas por ano)\n",
    "\n",
    "## Decisões de engenharia\n",
    "- **Sem falha silenciosa**: respostas inesperadas da API geram erro explicativo.\n",
    "- **Cache por indicador**: salva em `data/raw/indicators/{INDICATOR}.csv`.\n",
    "- **Robustez**: retries/backoff + timeouts adequados + pausa curta entre páginas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9272e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports + logging\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "logger = logging.getLogger(\"wdi_etl\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5bad33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações (indicadores, anos, paths)\n",
    "# Intervalo de anos\n",
    "YEARS = list(range(2000, 2021))\n",
    "DATE_RANGE = f\"{min(YEARS)}:{max(YEARS)}\"\n",
    "\n",
    "# Base da API\n",
    "BASE = \"https://api.worldbank.org/v2\"\n",
    "\n",
    "# Indicadores (WDI codes)\n",
    "INDICATORS = [\n",
    "    \"EG.ELC.ACCS.ZS\",       # Access to electricity (% of population)\n",
    "    \"AG.LND.AGRI.ZS\",       # Agricultural land (% of land area)\n",
    "    \"ER.H2O.FWVT.ZS\",       # Annual freshwater withdrawals, total (% of internal resources)\n",
    "    \"AG.LND.ARBL.ZS\",       # Arable land (% of land area)\n",
    "    \"AG.LND.FRST.ZS\",       # Forest area (% of land area)\n",
    "    \"EG.USE.ELEC.KH.PC\",    # Electric power consumption (kWh per capita)\n",
    "    \"EG.USE.PCAP.KG.OE\",    # Energy use (kg of oil equivalent per capita)\n",
    "    \"EG.ELC.RNEW.ZS\",       # Renewable electricity output (% of total electricity output)\n",
    "    \"EG.FEC.RNEW.ZS\",       # Renewable energy consumption (% of total final energy consumption)\n",
    "    \"SP.POP.GROW\",          # Population growth (annual %)\n",
    "    \"NY.GDP.PCAP.CD\",       # GDP per capita (current US$)\n",
    "    \"EN.ATM.CO2E.PC\",       # CO2 emissions (metric tons per capita)\n",
    "]\n",
    "\n",
    "# Pastas/arquivos\n",
    "DIR_RAW = Path(\"data/raw\")\n",
    "DIR_PROC = Path(\"data/processed\")\n",
    "DIR_INDICATORS = DIR_RAW / \"indicators\"\n",
    "\n",
    "PATH_LONG = DIR_RAW / \"wdi_long.csv\"\n",
    "PATH_WIDE = DIR_PROC / \"wdi_wide.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d7bb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-25 12:55:20,338 | INFO | Estrutura de pastas pronta: data/raw | data/processed | data/raw/indicators\n"
     ]
    }
   ],
   "source": [
    "# Criar pastas (idempotente)\n",
    "DIR_RAW.mkdir(parents=True, exist_ok=True)\n",
    "DIR_PROC.mkdir(parents=True, exist_ok=True)\n",
    "DIR_INDICATORS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(\"Estrutura de pastas pronta: %s | %s | %s\", DIR_RAW, DIR_PROC, DIR_INDICATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b84667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session com retry/backoff (robusto)\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "def build_session() -> requests.Session:\n",
    "    \"\"\"\n",
    "    Cria uma requests.Session com retry/backoff para lidar com:\n",
    "    - timeouts intermitentes\n",
    "    - 429 (rate limit) e 5xx\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "\n",
    "    retry = Retry(\n",
    "        total=8,\n",
    "        connect=8,\n",
    "        read=8,\n",
    "        backoff_factor=1.0,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\"],\n",
    "        raise_on_status=False,\n",
    "        respect_retry_after_header=True,\n",
    "    )\n",
    "\n",
    "    adapter = HTTPAdapter(max_retries=retry, pool_connections=20, pool_maxsize=20)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    session.mount(\"http://\", adapter)\n",
    "\n",
    "    # User-Agent ajuda alguns gateways/proxies e melhora rastreabilidade\n",
    "    session.headers.update({\"User-Agent\": \"CO2_Emissions_Prediction/1.0 (requests)\"})\n",
    "    return session\n",
    "\n",
    "SESSION = build_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed2d2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request JSON “à prova de falhas silenciosas”\n",
    "def request_json(url: str, params: Dict[str, Any], session: requests.Session = SESSION) -> Any:\n",
    "    \"\"\"\n",
    "    Faz um GET e retorna JSON, com validação forte.\n",
    "    Se a API retornar HTML, texto, ou um JSON fora do padrão, levanta erro com contexto.\n",
    "    \"\"\"\n",
    "    # timeouts: (conexão, leitura)\n",
    "    resp = session.get(url, params=params, timeout=(10, 180))\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    # Tenta parsear JSON\n",
    "    try:\n",
    "        data = resp.json()\n",
    "    except Exception:\n",
    "        snippet = resp.text[:300] if resp.text else \"\"\n",
    "        raise ValueError(\n",
    "            f\"Resposta não-JSON da API. url={url} params={params} status={resp.status_code} snippet={snippet!r}\"\n",
    "        )\n",
    "\n",
    "    # Alguns erros vêm como dict (ex.: {\"message\": ...})\n",
    "    if isinstance(data, dict):\n",
    "        raise ValueError(f\"API retornou dict (erro/limite). url={url} params={params} payload={data}\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd42e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paginação da API (sem engolir erro)\n",
    "def wb_get_all_pages(url: str, params: Dict[str, Any], session: requests.Session = SESSION) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Busca todas as páginas do endpoint World Bank v2.\n",
    "\n",
    "    Esperado: [meta, items]\n",
    "      - meta: contém 'page' e 'pages'\n",
    "      - items: lista de registros (ou None quando não há dados)\n",
    "    \"\"\"\n",
    "    params = dict(params)\n",
    "    params.setdefault(\"format\", \"json\")\n",
    "    params.setdefault(\"per_page\", 1000)  # menor = resposta mais leve\n",
    "\n",
    "    page = 1\n",
    "    out: List[dict] = []\n",
    "\n",
    "    while True:\n",
    "        params[\"page\"] = page\n",
    "        data = request_json(url, params=params, session=session)\n",
    "\n",
    "        # Validação do formato esperado\n",
    "        if not isinstance(data, list) or len(data) < 2:\n",
    "            raise ValueError(f\"Formato inesperado. url={url} params={params} payload_head={str(data)[:200]}\")\n",
    "\n",
    "        meta, items = data[0], data[1]\n",
    "\n",
    "        if items is None:\n",
    "            # Não há dados (fim)\n",
    "            break\n",
    "\n",
    "        if not isinstance(items, list):\n",
    "            raise ValueError(f\"Items inesperado (não é lista). url={url} params={params} items_head={str(items)[:200]}\")\n",
    "\n",
    "        out.extend(items)\n",
    "\n",
    "        pages = int(meta.get(\"pages\", 1))\n",
    "        if page >= pages:\n",
    "            break\n",
    "\n",
    "        page += 1\n",
    "        time.sleep(0.15)  # gentil com a API\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a1944f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Formato inesperado. url=https://api.worldbank.org/v2/country/BRA/indicator/EN.ATM.CO2E.PC params={'date': '2010:2012', 'format': 'json', 'per_page': 1000, 'page': 1} payload_head=[{'message': [{'id': '175', 'key': 'Invalid format', 'value': 'The indicator was not found. It may have been deleted or archived.'}]}]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Smoke test (rodar antes do download completo)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Smoke test: se isso falhar, não adianta rodar o ETL completo.\u001b[39;00m\n\u001b[32m      3\u001b[39m test_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/country/BRA/indicator/EN.ATM.CO2E.PC\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m test_items = \u001b[43mwb_get_all_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2010:2012\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSmoke test OK. Itens retornados:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_items))\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExemplo (1º item):\u001b[39m\u001b[33m\"\u001b[39m, test_items[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m test_items \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mwb_get_all_pages\u001b[39m\u001b[34m(url, params, session)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Validação do formato esperado\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < \u001b[32m2\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFormato inesperado. url=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m params=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m payload_head=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(data)[:\u001b[32m200\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m meta, items = data[\u001b[32m0\u001b[39m], data[\u001b[32m1\u001b[39m]\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m items \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# Não há dados (fim)\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Formato inesperado. url=https://api.worldbank.org/v2/country/BRA/indicator/EN.ATM.CO2E.PC params={'date': '2010:2012', 'format': 'json', 'per_page': 1000, 'page': 1} payload_head=[{'message': [{'id': '175', 'key': 'Invalid format', 'value': 'The indicator was not found. It may have been deleted or archived.'}]}]"
     ]
    }
   ],
   "source": [
    "# Smoke test (rodar antes do download completo)\n",
    "# Smoke test: se isso falhar, não adianta rodar o ETL completo.\n",
    "test_url = f\"{BASE}/country/BRA/indicator/EN.ATM.CO2E.PC\"\n",
    "test_items = wb_get_all_pages(test_url, params={\"date\": \"2010:2012\"})\n",
    "print(\"Smoke test OK. Itens retornados:\", len(test_items))\n",
    "print(\"Exemplo (1º item):\", test_items[0] if test_items else None)\n",
    "\n",
    "# Também testmos o endpoint \"all\" (que é o que usaremos para os indicadores)\n",
    "test_url_all = f\"{BASE}/country/all/indicator/EN.ATM.CO2E.PC\"\n",
    "test_items_all = wb_get_all_pages(test_url_all, params={\"date\": \"2010:2012\"})\n",
    "print(\"Smoke test (all) OK. Itens retornados:\", len(test_items_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar países e criar valid_country_codes\n",
    "countries_url = f\"{BASE}/country\"\n",
    "countries_items = wb_get_all_pages(countries_url, params={\"per_page\": 1000})\n",
    "\n",
    "df_countries = pd.json_normalize(countries_items)\n",
    "\n",
    "# Marcar agregados (normalmente region.value == \"Aggregates\")\n",
    "if \"region.value\" in df_countries.columns:\n",
    "    df_countries[\"is_aggregate\"] = df_countries[\"region.value\"].eq(\"Aggregates\")\n",
    "else:\n",
    "    df_countries[\"is_aggregate\"] = False\n",
    "\n",
    "valid_country_codes = set(df_countries.loc[~df_countries[\"is_aggregate\"], \"id\"].astype(str).tolist())\n",
    "\n",
    "logger.info(\"Total entidades (inclui agregados): %s\", df_countries.shape[0])\n",
    "logger.info(\"Total países/territórios (sem agregados): %s\", len(valid_country_codes))\n",
    "\n",
    "df_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função: baixar 1 indicador em formato longo\n",
    "def download_indicator_long(indicator_code: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Baixa um indicador para todos os países no intervalo DATE_RANGE,\n",
    "    devolvendo DataFrame longo padronizado.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE}/country/all/indicator/{indicator_code}\"\n",
    "    items = wb_get_all_pages(url, params={\"date\": DATE_RANGE})\n",
    "\n",
    "    rows = []\n",
    "    for it in items:\n",
    "        ccode = (it.get(\"country\") or {}).get(\"id\")\n",
    "        cname = (it.get(\"country\") or {}).get(\"value\")\n",
    "        icode = (it.get(\"indicator\") or {}).get(\"id\")\n",
    "        iname = (it.get(\"indicator\") or {}).get(\"value\")\n",
    "        year = it.get(\"date\")\n",
    "        val = it.get(\"value\")\n",
    "\n",
    "        if ccode is None or year is None:\n",
    "            continue\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Country Code\": str(ccode),\n",
    "                \"Country Name\": cname,\n",
    "                \"Indicator Code\": icode,\n",
    "                \"Indicator Name\": iname,\n",
    "                \"Year\": int(year),\n",
    "                \"Value\": val,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        df[\"Value\"] = pd.to_numeric(df[\"Value\"], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"Year\"]).copy()\n",
    "        df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92efcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache por indicador (não perder progresso)\n",
    "def indicator_cache_path(indicator_code: str) -> Path:\n",
    "    return DIR_INDICATORS / f\"{indicator_code}.csv\"\n",
    "\n",
    "def load_or_download_indicator(indicator_code: str, force: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carrega do cache se existir; caso contrário baixa e salva.\n",
    "    Se o download vier vazio, levanta erro (não salva cache vazio).\n",
    "    \"\"\"\n",
    "    path = indicator_cache_path(indicator_code)\n",
    "\n",
    "    if path.exists() and not force:\n",
    "        df = pd.read_csv(path)\n",
    "        df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"Year\"]).copy()\n",
    "        df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "        df[\"Value\"] = pd.to_numeric(df[\"Value\"], errors=\"coerce\")\n",
    "        return df\n",
    "\n",
    "    df = download_indicator_long(indicator_code)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\n",
    "            f\"Download vazio para indicador {indicator_code}. \"\n",
    "            \"Abortando para evitar cache vazio. Rode o smoke test e verifique a resposta da API.\"\n",
    "        )\n",
    "\n",
    "    df.to_csv(path, index=False)\n",
    "    logger.info(\"Cache salvo: %s | shape=%s\", path, df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir df_long (a partir do cache por indicador)\n",
    "dfs = []\n",
    "for i, ind in enumerate(INDICATORS, start=1):\n",
    "    logger.info(\"[%s/%s] Processando indicador: %s\", i, len(INDICATORS), ind)\n",
    "    dfi = load_or_download_indicator(ind, force=False)\n",
    "    logger.info(\"  -> linhas=%s | anos=%s..%s\", len(dfi), dfi[\"Year\"].min(), dfi[\"Year\"].max())\n",
    "    dfs.append(dfi)\n",
    "\n",
    "df_long = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Garantia de faixa de anos\n",
    "df_long = df_long[df_long[\"Year\"].between(min(YEARS), max(YEARS))].copy()\n",
    "\n",
    "if df_long.empty:\n",
    "    raise ValueError(\"df_long ficou vazio após concatenar. Isso indica falha sistemática no download/cache.\")\n",
    "\n",
    "df_long.to_csv(PATH_LONG, index=False)\n",
    "logger.info(\"Salvo: %s | shape=%s\", PATH_LONG, df_long.shape)\n",
    "\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza final + filtro de países + validação\n",
    "# Normalização defensiva\n",
    "df_long[\"Year\"] = pd.to_numeric(df_long[\"Year\"], errors=\"coerce\")\n",
    "df_long = df_long.dropna(subset=[\"Year\"]).copy()\n",
    "df_long[\"Year\"] = df_long[\"Year\"].astype(int)\n",
    "\n",
    "# Filtra anos (blindagem)\n",
    "df_long = df_long[df_long[\"Year\"].between(min(YEARS), max(YEARS))].copy()\n",
    "\n",
    "# Remove agregados (opcional)\n",
    "df_long = df_long[df_long[\"Country Code\"].isin(valid_country_codes)].copy()\n",
    "\n",
    "if df_long.empty:\n",
    "    raise ValueError(\n",
    "        \"df_long ficou vazio após filtro de países. \"\n",
    "        \"Provável divergência de códigos; inspecione df_long['Country Code'].unique() e valid_country_codes.\"\n",
    "    )\n",
    "\n",
    "assert df_long[\"Year\"].min() >= min(YEARS)\n",
    "assert df_long[\"Year\"].max() <= max(YEARS)\n",
    "\n",
    "logger.info(\"Após filtros: shape=%s\", df_long.shape)\n",
    "logger.info(\"Anos presentes: %s..%s\", df_long[\"Year\"].min(), df_long[\"Year\"].max())\n",
    "logger.info(\"Países: %s | Indicadores: %s\",\n",
    "            df_long[\"Country Code\"].nunique(),\n",
    "            df_long[\"Indicator Code\"].nunique())\n",
    "\n",
    "df_long.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1fc27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar df_wide estilo Kaggle + salvar\n",
    "df_wide = (\n",
    "    df_long.pivot_table(\n",
    "        index=[\"Country Code\", \"Country Name\", \"Indicator Code\", \"Indicator Name\"],\n",
    "        columns=\"Year\",\n",
    "        values=\"Value\",\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "base_cols = [\"Country Code\", \"Country Name\", \"Indicator Code\", \"Indicator Name\"]\n",
    "year_cols = [c for c in df_wide.columns if isinstance(c, int)]\n",
    "year_cols = sorted(year_cols)\n",
    "\n",
    "df_wide = df_wide[base_cols + year_cols]\n",
    "\n",
    "df_wide.to_csv(PATH_WIDE, index=False)\n",
    "logger.info(\"Salvo: %s | shape=%s\", PATH_WIDE, df_wide.shape)\n",
    "\n",
    "df_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0b934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3bf1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19c31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dd14819",
   "metadata": {},
   "source": [
    "## Configurações do ETL\n",
    "- INDICATORS: lista dos códigos WDI (fonte oficial)\n",
    "- YEARS: intervalo 2000–2020\n",
    "- PATH_LONG/PATH_WIDE: saídas em disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae18700",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICATORS = [\n",
    "    \"EG.ELC.ACCS.ZS\",       # Access to electricity (% of population)\n",
    "    \"AG.LND.AGRI.ZS\",       # Agricultural land (% of land area)\n",
    "    \"ER.H2O.FWVT.ZS\",       # Annual freshwater withdrawals, total (% of internal resources)\n",
    "    \"AG.LND.ARBL.ZS\",       # Arable land (% of land area)\n",
    "    \"AG.LND.FRST.ZS\",       # Forest area (% of land area)\n",
    "    \"EG.USE.ELEC.KH.PC\",    # Electric power consumption (kWh per capita)\n",
    "    \"EG.USE.PCAP.KG.OE\",    # Energy use (kg of oil equivalent per capita)\n",
    "    \"EG.ELC.RNEW.ZS\",       # Renewable electricity output (% of total electricity output)\n",
    "    \"EG.FEC.RNEW.ZS\",       # Renewable energy consumption (% of total final energy consumption)\n",
    "    \"SP.POP.GROW\",          # Population growth (annual %)\n",
    "    \"NY.GDP.PCAP.CD\",       # GDP per capita (current US$)\n",
    "    \"EN.ATM.CO2E.PC\",       # CO2 emissions (metric tons per capita)\n",
    "]\n",
    "\n",
    "YEARS = list(range(2000, 2021))\n",
    "DATE_RANGE = f\"{min(YEARS)}:{max(YEARS)}\"\n",
    "\n",
    "BASE = \"https://api.worldbank.org/v2\"\n",
    "\n",
    "PATH_LONG = Path(\"data/raw/wdi_long.csv\")\n",
    "PATH_WIDE = Path(\"data/processed/wdi_wide.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar pastas\n",
    "Path(\"data/raw\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "logger.info(\"Pastas data/raw e data/processed prontas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377483f9",
   "metadata": {},
   "source": [
    "## Função utilitária: paginação da APIA \n",
    "API do World Bank é paginada. A função abaixo:\n",
    "- percorre todas as páginas\n",
    "- acumula os itens\n",
    "- retorna uma lista única"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead85b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para capturar todas as paginas\n",
    "import time\n",
    "\n",
    "def wb_get_all_pages(url: str, params: dict, session: requests.Session = SESSION) -> list:\n",
    "    \"\"\"\n",
    "    Busca todas as páginas de um endpoint do World Bank (API v2),\n",
    "    com resiliência a timeouts e respostas lentas.\n",
    "    \"\"\"\n",
    "    params = dict(params)\n",
    "    params.setdefault(\"format\", \"json\")\n",
    "    params.setdefault(\"per_page\", 2000)  # menor = resposta mais leve e menos timeout\n",
    "\n",
    "    page = 1\n",
    "    out = []\n",
    "\n",
    "    while True:\n",
    "        params[\"page\"] = page\n",
    "\n",
    "        # timeout pode ser tupla: (connect_timeout, read_timeout)\n",
    "        resp = session.get(url, params=params, timeout=(10, 180))\n",
    "        resp.raise_for_status()\n",
    "\n",
    "        data = resp.json()\n",
    "\n",
    "        if not isinstance(data, list) or len(data) < 2 or data[1] is None:\n",
    "            break\n",
    "\n",
    "        meta, items = data[0], data[1]\n",
    "        out.extend(items)\n",
    "\n",
    "        pages = int(meta.get(\"pages\", 1))\n",
    "        if page >= pages:\n",
    "            break\n",
    "\n",
    "        page += 1\n",
    "\n",
    "        # “educado” com a API (ajuda estabilidade)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ebb9e",
   "metadata": {},
   "source": [
    "## Países e filtro de agregados\n",
    "Baixamos o catálogo de países para:\n",
    "- identificar e remover “Aggregates” (World, regiões, etc.)\n",
    "- manter apenas países/territórios como unidades de análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6be2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar países + valid_country_codes\n",
    "countries_url = f\"{BASE}/country\"\n",
    "countries_items = wb_get_all_pages(countries_url, params={\"per_page\": 20000})\n",
    "df_countries = pd.json_normalize(countries_items)\n",
    "\n",
    "# Agregados normalmente aparecem com region.value == \"Aggregates\"\n",
    "if \"region.value\" in df_countries.columns:\n",
    "    df_countries[\"is_aggregate\"] = df_countries[\"region.value\"].eq(\"Aggregates\")\n",
    "else:\n",
    "    df_countries[\"is_aggregate\"] = False  # fallback defensivo\n",
    "\n",
    "valid_country_codes = set(df_countries.loc[~df_countries[\"is_aggregate\"], \"id\"].tolist())\n",
    "\n",
    "logger.info(\"Total entidades (inclui agregados): %s\", df_countries.shape[0])\n",
    "logger.info(\"Total países/territórios (sem agregados): %s\", len(valid_country_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19ddad",
   "metadata": {},
   "source": [
    "## Função: download de 1 indicador (formato longo)\n",
    "Baixa um indicador WDI para todos os países, no intervalo configurado, e devolve:\n",
    "- Country Code,\n",
    "- Country Name,\n",
    "- Indicator Code,\n",
    "- Indicator Name,\n",
    "- Year,\n",
    "- Value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download de indicador (formato longo)\n",
    "\n",
    "def download_indicator_long(indicator_code: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Baixa um indicador WDI (todos países) para o intervalo DATE_RANGE.\n",
    "\n",
    "    Retorna um DataFrame no formato longo:\n",
    "      (Country, Indicator, Year) -> Value\n",
    "    \"\"\"\n",
    "    url = f\"{BASE}/country/all/indicator/{indicator_code}\"\n",
    "    items = wb_get_all_pages(url, params={\"date\": DATE_RANGE})\n",
    "\n",
    "    rows = []\n",
    "    for it in items:\n",
    "        # A API é semi-estruturada; usamos .get com fallback seguro\n",
    "        ccode = (it.get(\"country\") or {}).get(\"id\")\n",
    "        cname = (it.get(\"country\") or {}).get(\"value\")\n",
    "        icode = (it.get(\"indicator\") or {}).get(\"id\")\n",
    "        iname = (it.get(\"indicator\") or {}).get(\"value\")\n",
    "        year = it.get(\"date\")\n",
    "        val = it.get(\"value\")\n",
    "\n",
    "        if ccode is None or year is None:\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"Country Code\": ccode,\n",
    "            \"Country Name\": cname,\n",
    "            \"Indicator Code\": icode,\n",
    "            \"Indicator Name\": iname,\n",
    "            \"Year\": int(year),\n",
    "            \"Value\": val,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Normaliza tipos (Value pode vir None)\n",
    "    if not df.empty:\n",
    "        df[\"Value\"] = pd.to_numeric(df[\"Value\"], errors=\"coerce\")\n",
    "        df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6f01a",
   "metadata": {},
   "source": [
    "# Construção do dataset LONG (com cache)\n",
    "- Se data/raw/wdi_long.csv existir → carrega\n",
    "- Caso contrário → baixa todos os indicadores e salva\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir df_long com cache\n",
    "if PATH_LONG.exists():\n",
    "    df_long = pd.read_csv(PATH_LONG)\n",
    "    df_long[\"Year\"] = df_long[\"Year\"].astype(int)\n",
    "    df_long[\"Value\"] = pd.to_numeric(df_long[\"Value\"], errors=\"coerce\")\n",
    "    logger.info(\"Carregado do cache: %s | shape=%s\", PATH_LONG, df_long.shape)\n",
    "else:\n",
    "    dfs = []\n",
    "    for i, ind in enumerate(INDICATORS, start=1):\n",
    "        logger.info(\"[%s/%s] Baixando indicador: %s\", i, len(INDICATORS), ind)\n",
    "        dfs.append(download_indicator_long(ind))\n",
    "\n",
    "    df_long = pd.concat(dfs, ignore_index=True)\n",
    "    df_long = df_long[df_long[\"Year\"].between(min(YEARS), max(YEARS))]\n",
    "\n",
    "    df_long.to_csv(PATH_LONG, index=False)\n",
    "    logger.info(\"Salvo: %s | shape=%s\", PATH_LONG, df_long.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf33728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa847c5",
   "metadata": {},
   "source": [
    "## Filtro final + checagens\n",
    "### Limpeza final + checagens\n",
    "- Remove agregados (opcional)\n",
    "- Valida intervalo de anos\n",
    "- Reporta cardinalidades úteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape:\", df_long.shape)\n",
    "print(\"Year dtype:\", df_long[\"Year\"].dtype)\n",
    "print(\"Year min/max:\", df_long[\"Year\"].min(), df_long[\"Year\"].max())\n",
    "print(\"Year nulos:\", df_long[\"Year\"].isna().sum())\n",
    "\n",
    "print(\"shape após filtro de anos:\", df_long[df_long[\"Year\"].between(min(YEARS), max(YEARS))].shape)\n",
    "print(\"shape após filtro de países:\", df_long[df_long[\"Country Code\"].isin(valid_country_codes)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f896547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar Year\n",
    "df_long[\"Year\"] = pd.to_numeric(df_long[\"Year\"], errors=\"coerce\")\n",
    "df_long = df_long.dropna(subset=[\"Year\"]).copy()\n",
    "df_long[\"Year\"] = df_long[\"Year\"].astype(int)\n",
    "\n",
    "# Filtrar anos primeiro\n",
    "df_long = df_long[df_long[\"Year\"].between(min(YEARS), max(YEARS))].copy()\n",
    "\n",
    "# Só então filtrar países (e validar se não zerou)\n",
    "df_long = df_long[df_long[\"Country Code\"].isin(valid_country_codes)].copy()\n",
    "\n",
    "if df_long.empty:\n",
    "    raise ValueError(\"df_long ficou vazio após filtros (anos/país). Comente o filtro de países ou revise valid_country_codes.\")\n",
    "\n",
    "# Agora sim faz sentido validar min/max\n",
    "assert df_long[\"Year\"].min() >= min(YEARS)\n",
    "assert df_long[\"Year\"].max() <= max(YEARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar filtro e validar códigos de país\n",
    "# Garantir tipo correto e remover anos inválidos\n",
    "df_long[\"Year\"] = pd.to_numeric(df_long[\"Year\"], errors=\"coerce\")\n",
    "df_long = df_long.dropna(subset=[\"Year\"]).copy()\n",
    "df_long[\"Year\"] = df_long[\"Year\"].astype(int)\n",
    "\n",
    "# Reaplicar filtro de anos (blindagem)\n",
    "df_long = df_long[df_long[\"Year\"].between(min(YEARS), max(YEARS))].copy()\n",
    "\n",
    "# Agora sim: filtro de países (opcional)\n",
    "df_long = df_long[df_long[\"Country Code\"].isin(valid_country_codes)].copy()\n",
    "\n",
    "assert df_long[\"Year\"].min() >= min(YEARS)\n",
    "assert df_long[\"Year\"].max() <= max(YEARS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
